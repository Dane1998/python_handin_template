{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model with dropout on the cifar10 dataset\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import SGD\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "\t# load dataset\n",
    "\t(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
    "\t# one hot encode target values\n",
    "\ttrainY = to_categorical(trainY)\n",
    "\ttestY = to_categorical(testY)\n",
    "\treturn trainX, trainY, testX, testY\n",
    "\n",
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "\t# convert from integers to floats\n",
    "\ttrain_norm = train.astype('float32')\n",
    "\ttest_norm = test.astype('float32')\n",
    "\t# normalize to range 0-1\n",
    "\ttrain_norm = train_norm / 255.0\n",
    "\ttest_norm = test_norm / 255.0\n",
    "\t# return normalized images\n",
    "\treturn train_norm, test_norm\n",
    "\n",
    "\n",
    "# define cnn model\n",
    "def define_model():\n",
    "\tmodel = Sequential()\n",
    "\t# ...\n",
    "\treturn model\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "\t# plot loss\n",
    "\tpyplot.subplot(211)\n",
    "\tpyplot.title('Cross Entropy Loss')\n",
    "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "\t# plot accuracy\n",
    "\tpyplot.subplot(212)\n",
    "\tpyplot.title('Classification Accuracy')\n",
    "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "\t# save plot to file\n",
    "\tfilename = sys.argv[0].split('/')[-1]\n",
    "\tpyplot.savefig(filename + '_plot.png')\n",
    "\tpyplot.close()\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# prepare pixel data\n",
    "\ttrainX, testX = prep_pixels(trainX, testX)\n",
    "\t# define model\n",
    "\tmodel = define_model()\n",
    "\t# fit model\n",
    "\thistory = model.fit(trainX, trainY, epochs=100, batch_size=64, validation_data=(testX, testY), verbose=0)\n",
    "\t# evaluate model\n",
    "\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cnn model\n",
    "def define_model1():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(10, activation='softmax'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define cnn model\n",
    "def define_model2():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(10, activation='softmax'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define cnn model\n",
    "def define_model3():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(10, activation='softmax'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 1.8418 - accuracy: 0.3384 - val_loss: 1.3901 - val_accuracy: 0.5053\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 1.3265 - accuracy: 0.5280 - val_loss: 1.2358 - val_accuracy: 0.5611\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 1.1445 - accuracy: 0.5952 - val_loss: 1.1126 - val_accuracy: 0.6065\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 1.0245 - accuracy: 0.6369 - val_loss: 1.0122 - val_accuracy: 0.6442\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.9132 - accuracy: 0.6812 - val_loss: 1.0322 - val_accuracy: 0.6372\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.8399 - accuracy: 0.7042 - val_loss: 0.9519 - val_accuracy: 0.6672\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.7461 - accuracy: 0.7397 - val_loss: 0.9587 - val_accuracy: 0.6702\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.6736 - accuracy: 0.7669 - val_loss: 0.9582 - val_accuracy: 0.6715\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.5986 - accuracy: 0.7959 - val_loss: 0.9548 - val_accuracy: 0.6801\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.5322 - accuracy: 0.8167 - val_loss: 0.9997 - val_accuracy: 0.6784\n",
      "> 67.840\n"
     ]
    }
   ],
   "source": [
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# prepare pixel data\n",
    "\ttrainX, testX = prep_pixels(trainX, testX)\n",
    "\t# define model\n",
    "\tmodel = define_model1()\n",
    "\t# fit model\n",
    "\thistory = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=1)\n",
    "\t# evaluate model\n",
    "\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.8057 - accuracy: 0.3519 - val_loss: 1.3140 - val_accuracy: 0.5229\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.2335 - accuracy: 0.5617 - val_loss: 1.1322 - val_accuracy: 0.6029\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.0487 - accuracy: 0.6312 - val_loss: 1.0259 - val_accuracy: 0.6404\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 0.9080 - accuracy: 0.6840 - val_loss: 0.9132 - val_accuracy: 0.6817\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.8115 - accuracy: 0.7182 - val_loss: 0.9229 - val_accuracy: 0.6741\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.7206 - accuracy: 0.7519 - val_loss: 0.8595 - val_accuracy: 0.7056\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.6403 - accuracy: 0.7796 - val_loss: 0.8197 - val_accuracy: 0.7241\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5637 - accuracy: 0.8030 - val_loss: 0.8533 - val_accuracy: 0.7200\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.4987 - accuracy: 0.8272 - val_loss: 0.8391 - val_accuracy: 0.7191\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.4323 - accuracy: 0.8520 - val_loss: 0.8866 - val_accuracy: 0.7183\n",
      "> 71.830\n"
     ]
    }
   ],
   "source": [
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# prepare pixel data\n",
    "\ttrainX, testX = prep_pixels(trainX, testX)\n",
    "\t# define model\n",
    "\tmodel = define_model2()\n",
    "\t# fit model\n",
    "\thistory = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=1)\n",
    "\t# evaluate model\n",
    "\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.8415 - accuracy: 0.3301 - val_loss: 1.3577 - val_accuracy: 0.5112\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 1.2898 - accuracy: 0.5443 - val_loss: 1.1178 - val_accuracy: 0.6035\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 1.0606 - accuracy: 0.6261 - val_loss: 1.0201 - val_accuracy: 0.6332\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.9150 - accuracy: 0.6779 - val_loss: 0.9743 - val_accuracy: 0.6566\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.8137 - accuracy: 0.7165 - val_loss: 0.8869 - val_accuracy: 0.6872\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.7161 - accuracy: 0.7511 - val_loss: 0.8761 - val_accuracy: 0.6959\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.6338 - accuracy: 0.7782 - val_loss: 0.8340 - val_accuracy: 0.7166\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.5659 - accuracy: 0.8004 - val_loss: 0.8378 - val_accuracy: 0.7123\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.4993 - accuracy: 0.8274 - val_loss: 0.8219 - val_accuracy: 0.7238\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.4329 - accuracy: 0.8486 - val_loss: 0.8632 - val_accuracy: 0.7231\n",
      "> 72.310\n"
     ]
    }
   ],
   "source": [
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# prepare pixel data\n",
    "\ttrainX, testX = prep_pixels(trainX, testX)\n",
    "\t# define model\n",
    "\tmodel = define_model3()\n",
    "\t# fit model\n",
    "\thistory = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=1)\n",
    "\t# evaluate model\n",
    "\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define cnn model\n",
    "def define_model4():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Dense(10, activation='softmax'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# prepare pixel data\n",
    "\ttrainX, testX = prep_pixels(trainX, testX)\n",
    "\t# define model\n",
    "\tmodel = define_model4()\n",
    "\t# fit model\n",
    "\thistory = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=0)\n",
    "\t# evaluate model\n",
    "\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define cnn model\n",
    "def define_model5():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Dropout(0.3))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Dropout(0.4))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(Dense(10, activation='softmax'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# prepare pixel data\n",
    "\ttrainX, testX = prep_pixels(trainX, testX)\n",
    "\t# define model\n",
    "\tmodel = define_model5()\n",
    "\t# create data generator\n",
    "\tdatagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
    "\t# prepare iterator\n",
    "\tit_train = datagen.flow(trainX, trainY, batch_size=64)\n",
    "\t# fit model\n",
    "\tsteps = int(trainX.shape[0] / 64)\n",
    "\thistory = model.fit_generator(it_train, steps_per_epoch=steps, epochs=10, validation_data=(testX, testY), verbose=0)\n",
    "\t# evaluate model\n",
    "\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
